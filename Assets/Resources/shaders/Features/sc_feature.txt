// SUGGESTIVE CONTAOURS 
// Required:
//
//			_PrincipalCurvatureBuffer;
//			_InterpolatedNormalsBuffer;
//
//		_sc_FeatureSize
//		_sc_ContourLimit
//		_sc_SuggestiveContourLimit
//		_sc_DwKrLimit
//		_sc_JeroenMethod

#if IN_sc_FEATURE_DETECTION_MODE != DETECTION_MODE_VERTEX
#error "Suggestive contours can only be detected in vertex"
#endif

#if ! (IN_sc_FEATURE_APPLY_MODE == APPLY_MODE_FILLING || IN_sc_FEATURE_APPLY_MODE == APPLY_MODE_LINE_FILLING)
#error "Suggestive contours can only be applied by filling or line filling"
#endif



			struct sc_contoursComputationInput {
				float ndotv;
				float kr;
				float dwkr;
			};

			sc_contoursComputationInput sc_make_contoursComputationInput(float ndotv, float kr, float dwkr) {
				sc_contoursComputationInput input;
				input.ndotv = ndotv;
				input.kr = kr;
				input.dwkr = dwkr;
				return input;
			}

			sc_contoursComputationInput sc_workOutContoursComputationInput(float3 viewDir, float3 objectNrm, PrincipalCurvatureInfo info) {
				float3 worldNrm = normalize(mul((float3x3)unity_ObjectToWorld, normalize(objectNrm))); //n(p) z (1)
				float ndotv = dot(worldNrm,viewDir); //cos(alpha)

				// w to powinno być - w defined as the (unnormalized) projection of the view vector v onto the tangent plane at p
				// i rzeczywiście, to jest taki niepełny wzór na rzucowanie, ale zauważcie że potem robimy normalizacje
				float3 w = normalize(viewDir - worldNrm * dot(viewDir, worldNrm));
				float u = dot(w,(info.direction1)); //cos(fi) Fi więc jest kątem między w a direction1
				float v = dot(w,(info.direction2)); //sin(fi) direction1 i direction2 są zawsze ortogonalne
				float u2 = u * u; //cos(fi)2
				float v2 = v*v; // sin(fi)2 
				float kr = (info.value1*u2) + (info.value2*v2); //wzór (6)

				float u_v = u*v;
				// obliczanie pochodnych. 
				// Opis obliczenia pochodnych, bardzo ładne ale po holendersku, znaleźć można w pracy pana Jeroena Baerta, strona 30, plik masterproef.pdf
				float dwII = (u2 *u *info.derivative.x) + (3 * u * u_v *info.derivative.y) + (3 * u_v * v * info.derivative.z) + (v*v2*info.derivative.w);
				float dwkr = dwII + 2 * info.value1 * info.value2 * ndotv / sqrt(1 - pow(ndotv, 2));
				// wzór 4.11, masterproef.pdf  
				// warto zauważyć, że zgodnie z 4.10i4.11 cos(fi) = sqrt(1-pow(ndotv, 2))
				//DwKr ze wzoru (2)
				return sc_make_contoursComputationInput(ndotv, kr, dwkr);
			}

// algorithm-native functions

struct sc_VertexOutBuffer{
	sc_contoursComputationInput contoursInput;
};
#define	Transfer_sc_VertexOutBuffer 1

sc_VertexOutBuffer sc_VertexFilter(VertexSituation situation, appdata v) {

	float3 vertexWorldPos = mul(unity_ObjectToWorld , v.pos);
	float3 viewDir = normalize(_WorldSpaceCameraPos - vertexWorldPos); //camera to vertex v(p) z (1)

	float3 objectNrm = _InterpolatedNormalsBuffer[situation.vid];

	PrincipalCurvatureInfo info = _PrincipalCurvatureBuffer[situation.vid];

	sc_VertexOutBuffer buffer;
	buffer.contoursInput = sc_workOutContoursComputationInput(viewDir, objectNrm, info);
	return buffer;
}

//////////// GEOMETRY SHADER
struct sc_GeometryOutBuffer {
	sc_contoursComputationInput contoursInput;
};
#define	Transfer_sc_GeometryOutBuffer 1


void sc_GeometryFilter(sc_VertexOutBuffer inBuffer[3], inout sc_GeometryOutBuffer outBuffer[3], geometry_edge_situation s, geometry_camera_situation camera_situation, uint triangleIndex, inout bool shouldCreateFins, inout sc_GeometryOutBuffer finBuffer){
	outBuffer[triangleIndex].contoursInput = inBuffer[triangleIndex].contoursInput; // we simply copy
	finBuffer.contoursInput = sc_make_contoursComputationInput(0,0,0);
}

////////////////////// PIXEL SHADER

#if IN_USE_GEOMETRY_SHADER
	#define sc_FragmentInBuffer sc_GeometryOutBuffer
#else
	#define sc_FragmentInBuffer sc_VertexOutBuffer
#endif

void sc_FragmentSurfaceLineFilter(FragmentSurfaceLineSituation situation, sc_FragmentInBuffer scIn, inout float4 color) {
}

void sc_FragmentFinFilter( sc_FragmentInBuffer scIn, inout float4 color) {
}

void sc_FragmentFillingFilter(sc_FragmentInBuffer buffer, inout float4 color){

				sc_contoursComputationInput contoursInput = buffer.contoursInput;

				float fz = _sc_FeatureSize;
				float c_limit = _sc_ContourLimit;
				float sc_limit = _sc_SuggestiveContourLimit;
				float dwkr_limit = _sc_DwKrLimit;

				float kr = fz * abs(contoursInput.kr);
				float dwkr = fz*fz*contoursInput.dwkr;
				float dwkr2 = (dwkr - dwkr*pow(contoursInput.ndotv, 2));

#if IN_sc_FEATURE_APPLY_MODE == APPLY_MODE_FILLING
				//contours
				// podzielenie przez kr jest sprytne, i sprawia że "grubosc" konturu jest stała w różnych miejscach
				float contour_limit = c_limit*(pow(contoursInput.ndotv, 2.0) / kr);

				float sc_limit2;
				if (_sc_JeroenMethod > 0) {
					sc_limit2 = sc_limit*(kr / dwkr2);
				}
				else {
					sc_limit2 = sc_limit*(dwkr);
				}

				if (contour_limit < 1) {
					color = float4(1,1,0.5,1);
				}
				// alternatywą dla drugiej części członu byłoby dwkr > dwkr_limit, co odpowiada (2)
				else if (sc_limit2 < 1 && dwkr2 > dwkr_limit) {
					color = float4(0.5,1,0.5,1);
				}
#elif IN_sc_FEATURE_APPLY_MODE == APPLY_MODE_LINE_FILLING

				if( abs( contoursInput.kr) < sc_limit * fwidth(contoursInput.kr)) {
					if( contoursInput.dwkr > 0){
						if( contoursInput.ndotv < dwkr_limit){
							color = float4(0.5,1,0.5,1); 
						}
					}
				}
#endif

}
